---
title: Redis缓存浓缩篇
categories:
- 中间件
tags:
- Redis缓存
---





- [Redis数据类型](##1)
- [Redis数据存储](##2)
- [Redis主从配置](##3)
- [哨兵sentinel](##4)
- [哈希槽](##5)
- [集群](##6)
- [Redis持久化](##7)
- [分布式锁](##8)
- [了解Reids多路复用](##9)
<!--more-->




<span id="#1"></span>
### Redis数据类型
string,list,set及zset(sorted set)和Hash。

<span id="#2"></span>
### **Redis数据存储**
- redis的存储分为内存存储、磁盘存储和log文件三部分，配置文件中有三个参数对其进行配置。
- save seconds updates，save配置，指出在多长时间内，有多少次更新操作，就将数据同步到数据文件。这个可以多个条件配合，比如默认配置文件中的设置，就设置了三个条件。
- appendonly yes/no ，appendonly配置，指出是否在每次更新操作后进行日志记录，如果不开启，可能会在断电时导致一段时间内的数据丢失。因为redis本身同步数据文件是按上面的save条件来同步的，所以有的数据会在一段时间内只存在于内存中。
- appendfsync no/always/everysec ，appendfsync配置，no表示等操作系统进行数据缓存同步到磁盘，always表示每次更新操作后手动调用fsync()将数据写到磁盘，everysec表示每秒同步一次。


<span id="#3"></span>
### Redis主从配置
redis支持master-slave的主从配置，配置方法是在从机的配置文件中指定slaveof参数为主机的ip和port即可。


<span id="#4"></span>
### 哨兵sentinel
redis的sentinel系统用于管理多个redis服务器，该系统主要执行三个任务：监控、提醒、自动故障转移。
1. 监控（Monitoring）： Redis Sentinel实时监控主服务器和从服务器运行状态，并且实现自动切换。
2. 提醒（Notification）：当被监控的某个 Redis 服务器出现问题时， Redis Sentinel 可以向系统管理员发送通知， 也可以通过 API 向其他程序发送通知。
3. 自动故障转移（Automatic failover）： 当一个主服务器不能正常工作时，Redis Sentinel 可以将一个从服务器升级为主服务器， 并对其他从服务器进行配置，让它们使用新的主服务器。当应用程序连接Redis 服务器时， Redis Sentinel会告之新的主服务器地址和端口。

> 注意：在使用sentinel监控主从节点的时候，从节点需要是使用动态方式配置的，如果直接修改配置文件，后期sentinel实现故障转移的时候会出问题。


<span id="#5"></span>
### 哈希槽
一个 Redis 集群包含 16384 个哈希槽（hash slot），数据库中的每个数据都属于这16384个哈希槽中的一个。集群使用公式 CRC16(key) % 16384 来计算键 key 属于哪个槽。集群中的每一个节点负责处理一部分哈希槽。
哈希槽的好处：
1. 便于添加删除节点，只需处理槽位的转移，但不会自动进行，需要人工配置；
2. 对比一致性哈希，扩展节点需要重新哈希分配数据，哈希槽更便于扩展节点；
3. 由用户自己定义分配。例如机器硬盘小的，可以分配少一点槽位，硬盘大的可以分配多一点。


<span id="#6"></span>
### 集群
- 集群至少需要3主3从，且每个实例使用不同的配置文件，主从不用配置，集群会自己选。
- 集群中的每个节点都有1个至N个复制品，其中一个为主节点，其余的为从节点，如果主节点下线了，集群就会把这个主节点的一个从节点设置为新的主节点，继续工作。
- 修改拷贝的redis.conf文件，配置开启集群，修改端口
```
    daemonize yes
    port 6379 #只有端口不同，其他相同
    cluster-enabled yes
    cluster-config-file nodes.conf
    cluster-node-timeout 5000
```
- 根据添加节点类型的不同，有两种方法来添加新节点
1. 主节点：创建一个空节点，启动节点，加入集群，使用redis-trib程序，将集群中的某些哈希槽移动到新节点里面；
2. 从节点：创建一个空节点，启动节点，加入集群，使用redis-cli命令把这个新节点设置成集群中某个主节点的复制品。


<span id="#7"></span>
### Redis持久化
Redis4.0之前持久化的方式有两种：RDB 和 AOF
Redis4.0新增混合持久化：RDB-AOF

**RDB**
- RDB就是Snapshot快照存储，是默认的持久化方式。
- 可理解为半持久化模式，即按照一定的策略周期性的将数据保存到磁盘。
- 对应产生的数据文件为dump.rdb，通过配置文件中的save参数来定义快照的周期。

下面是默认的快照设置：
```
save 900 1    #当有一条Keys数据被改变时，900秒刷新到Disk一次
save 300 10   #当有10条Keys数据被改变时，300秒刷新到Disk一次
save 60 10000 #当有10000条Keys数据被改变时，60秒刷新到Disk一次
```
Redis的RDB文件不会坏掉，因为其写操作是在一个新进程中进行的。
RDB有它的不足，就是一旦数据库出现问题，那么我们的RDB文件中保存的数据并不是全新的。从上次RDB文件生成到Redis停机这段时间的数据全部丢掉了。


**AOF**
- AOF(Append-Only File)比RDB方式有更好的持久化性。
- 由于在使用AOF持久化方式时，Redis会将每一个收到的写命令都通过Write函数追加到文件中，类似于MySQL的binlog。
- 当Redis重启是会通过重新执行文件中保存的写命令来在内存中重建整个数据库的内容。
- 可读性好，文本追加。

对应的设置参数为：
$ vim /opt/redis/etc/redis_6379.conf
```
appendonly yes       #启用AOF持久化方式
appendfilename appendonly.aof #AOF文件的名称，默认为appendonly.aof
# appendfsync always #每次收到写命令就立即强制写入磁盘，是最有保证的完全的持久化，但速度也是最慢的，一般不推荐使用。
appendfsync everysec #每秒钟强制写入磁盘一次，在性能和持久化方面做了很好的折中，是受推荐的方式。
# appendfsync no     #完全依赖OS的写入，一般为30秒左右一次，性能最好但是持久化最没有保证，不被推荐。
```

**压缩AOF**
- AOF的完全持久化方式同时也带来了另一个问题，持久化文件会变得越来越大。
- 比如我们调用INCR test命令100次，文件中就必须保存全部的100条命令，但其实99条都是多余的。
- 因为要恢复数据库的状态其实文件中保存一条SET test 100就够了。
- 为了压缩AOF的持久化文件，Redis提供了bgrewriteaof命令。
- 收到此命令后Redis将使用与快照类似的方式将内存中的数据以命令的方式保存到临时文件中，最后替换原来的文件，以此来实现控制AOF文件的增长。
- 由于是模拟快照的过程，因此在重写AOF文件时并没有读取旧的AOF文件，而是将整个内存中的数据库内容用命令的方式重写了一个新的AOF文件。

对应的设置参数为:
$ vim /opt/redis/etc/redis_6379.conf
```
no-appendfsync-on-rewrite yes   #在日志重写时，不进行命令追加操作，而只是将其放在缓冲区里，避免与命令的追加造成DISK IO上的冲突。
auto-aof-rewrite-percentage 100 #当前AOF文件大小是上次日志重写得到AOF文件大小的二倍时，自动启动新的日志重写过程。
auto-aof-rewrite-min-size 64mb  #当前AOF文件启动新的日志重写过程的最小值，避免刚刚启动Reids时由于文件尺寸较小导致频繁的重写。
```

**在数据恢复方面：**
RDB的启动时间会更短，原因有两个：
- 一是RDB文件中每一条数据只有一条记录，不会像AOF日志那样可能有一条数据的多次操作记录。所以每条数据只需要写一次就行了。
- 另一个原因是RDB文件的存储格式和Redis数据在内存中的编码格式是一致的，不需要再进行数据编码工作，所以在CPU消耗上要远小于AOF日志的加载。

目前，通常的设计思路是利用Replication机制来弥补aof、snapshot性能上的不足，达到了数据可持久化。
- 即Master上Snapshot和AOF都不做，来保证Master的读写性能，而Slave上则同时开启Snapshot和AOF来进行持久化，保证数据的安全性。
- 可以在Slave上仅开启Snapshot来进行本地化，同时可以考虑将save中的频率调高一些或者调用一个计划任务来进行定期bgsave的快照存储，来尽可能的保障本地化数据的完整性。
- 在这样的架构下，如果仅仅是Master挂掉，Slave完整，数据恢复可达到100%。

https://blog.csdn.net/u011204847/article/details/51307044


**RDB-AOF**
// TODO


<span id="#8"></span>
### 分布式锁
需满足条件：
1. 原子性操作，保证只有一个客户端线程能获取锁；
2. 避免死锁，设置过期时间主动解锁，解决异常中断后长期持有锁；
3. 正确释放锁，设置value值，保证释放锁是当前持有锁；
4. 容错性，单节点实现分布式锁有风险，缓存集群存在宕机的可能，大多数节点正常工作实现锁（宕机重启后节点够多，这过程而导致同时多个客户端持有锁，概率太小，人工介入即可）；

**实现方法思路**
**一、获取锁**
1. key，固定值，基于setnx命令；
2. value，随机数或requestId（UUID），用于释放锁，解铃还须系铃人；
3. expireTime，设置过期时间，用于强制释放锁，避免死锁；
4. 封装方法实现在多个节点成功获取锁，超过半数则成功，否则失败并删除键值；

**二、释放锁**
1. key，同获取锁；
2. value，同获取锁，只有一致才能释放；
3. 脚本实现对比value值和删除锁。原子性操作，redis支持lua脚本；

**三、锁等待**
1. 持有锁较久，睡眠循环等待；
2. 设置超时等待，限时内获取不到锁返回失败；


<span id="#9"></span>
### 了解Reids多路复用
- I/O 多路复用模块封装了底层的 select、epoll、avport 以及 kqueue 这些 I/O 多路复用函数，为上层提供了相同的接口。
- Redis 会优先选择时间复杂度为 $O(1)$ 的 I/O 多路复用函数作为底层实现，包括 Solaries 10 中的 evport、Linux 中的 epoll 和 macOS/FreeBSD 中的 kqueue，上述的这些函数都使用了内核内部的结构，并且能够服务几十万的文件描述符。
- 但是如果当前编译环境没有上述函数，就会选择 select 作为备选方案，由于其在使用时会扫描全部监听的描述符，所以其时间复杂度较差 $O(n)$，并且只能同时服务 1024 个文件描述符，所以一般并不会以 select 作为第一方案使用。



by xuyuanfa